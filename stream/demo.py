import streamlit as st
from openai import OpenAI

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œé…ç½®
st.set_page_config(page_title="åƒé—®Plus", layout="wide")
st.title("ğŸ¤– é€šä¹‰åƒé—®Plus")

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = OpenAI(
    api_key="sk-139a40229c0e4bd58191a7a2f8c9c8f3",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# åˆå§‹åŒ–èŠå¤©å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

def get_completion(text):
    try:
        completion = client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                *st.session_state.messages,  # åŒ…å«å†å²æ¶ˆæ¯
                {"role": "user", "content": text},
            ],
            stream=True,
            stream_options={"include_usage": True}
        )
        return completion
    except Exception as e:
        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è·å–ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # è·å–AIå“åº”
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # å¤„ç†æµå¼å“åº”
        response = get_completion(prompt)
        if response:
            try:
                for chunk in response:
                    if hasattr(chunk, 'choices') and chunk.choices and hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
                        full_response += chunk.choices[0].delta.content
                        message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                
                # åªæœ‰åœ¨æˆåŠŸè·å–åˆ°å“åº”æ—¶æ‰æ·»åŠ åˆ°å†å²è®°å½•
                if full_response:
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                else:
                    st.error("æœªèƒ½è·å–åˆ°æœ‰æ•ˆçš„å“åº”")
            except Exception as e:
                st.error(f"å¤„ç†å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

# æ·»åŠ æ¸…é™¤èŠå¤©æŒ‰é’®
if st.sidebar.button("æ¸…é™¤èŠå¤©å†å²"):
    st.session_state.messages = []
    st.experimental_rerun()

# æ·»åŠ ä¾§è¾¹æ è¯´æ˜
with st.sidebar:
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜
    1. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥æ‚¨çš„é—®é¢˜
    2. æŒ‰å›è½¦é”®æˆ–ç‚¹å‡»å‘é€æŒ‰é’®
    3. ç­‰å¾…AIåŠ©æ‰‹çš„å›ç­”
    4. å¯ä»¥ç‚¹å‡»"æ¸…é™¤èŠå¤©å†å²"é‡æ–°å¼€å§‹å¯¹è¯
    
    ### åŠŸèƒ½ç‰¹ç‚¹
    - æ”¯æŒæµå¼è¾“å‡º
    - ä¿å­˜èŠå¤©å†å²
    - æ”¯æŒMarkdownæ ¼å¼
    """)